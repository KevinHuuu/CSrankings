{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "HW5_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinHuuu/CSrankings/blob/emeryberger-patch-1/HW5_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyClcLuqjKb8",
        "colab_type": "text"
      },
      "source": [
        "# Homework 5: Transition-Based Dependency Parser\n",
        "\n",
        "**Due April 6, 2020 at 11:59pm**\n",
        "\n",
        "In this homework, you will be implementing parts of a transition-based dependency parser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJLC8xn_jKcA",
        "colab_type": "text"
      },
      "source": [
        "**Before beginning, please switch your Colab session to a GPU runtime** \n",
        "\n",
        "Go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "\n",
        "**Also, remember to upload our dataset**\n",
        "\n",
        "Click the Files icon > Upload > Upload the three `.conll` files that you have downloaded from bCourses:Files/HW5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iICR_E0jKcC",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1TYSGJVjKcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNQBqiH3jKcH",
        "colab_type": "code",
        "outputId": "901dc513-b5d9-495c-ac01-80e2761a8c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# if this cell prints \"Running on cpu\", you must switch runtime environments\n",
        "# go to Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0t2Z1vRjKcL",
        "colab_type": "text"
      },
      "source": [
        "### Download pretrained word embeddings\n",
        "\n",
        "In this assignment, we will still be using [GloVe](https://nlp.stanford.edu/projects/glove/) pretrained word embeddings.\n",
        "\n",
        "**Note**: this section will take *several minutes*, since the embedding files are large. Files in Colab may be cached between sessions, so you may or may not need to redownload the files each time you reconnect. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u26MFsgjKcM",
        "colab_type": "code",
        "outputId": "eb871da8-17ca-4da0-afa2-04d75840de81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-16 04:22:44--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-03-16 04:22:44--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-03-16 04:22:45--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.01MB/s    in 6m 30s  \n",
            "\n",
            "2020-03-16 04:29:14 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njKMNfHmjKcR",
        "colab_type": "text"
      },
      "source": [
        "### Question 1. Checking for Projectivity\n",
        "In this question, you are supposed to implement the `is_projective` function below.\n",
        "* A tree structure is said to be projective if there are no crossing dependency edges and/or projection lines. \n",
        "* The function should take a sentence as input and returns True if and only if the tree is projective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fME7S_whjKcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_projective(toks):\n",
        "    \"\"\"\n",
        "    params: toks is a list of (idd, tok, pos, head, lab) for a sentence\n",
        "    return True if and only if the sentence has a projective dependency tree\n",
        "    \"\"\"\n",
        "\n",
        "    # Implement your code below\n",
        "    \n",
        "    ##################\n",
        "    # YOUR CODE HERE\n",
        "    ##################\n",
        "\n",
        "    ##################\n",
        "    # Staff Solution\n",
        "    ##################\n",
        "\n",
        "    def reachable(i, head, heads):\n",
        "        cur = i\n",
        "        while cur != 0:\n",
        "            cur = heads[cur]\n",
        "            if cur == head: return True\n",
        "            \n",
        "        return False\n",
        "\n",
        "\n",
        "    heads = {}\n",
        "\n",
        "    for position in toks:\n",
        "        (idd, tok, pos, head, lab) = position\n",
        "        if idd not in heads: heads[idd] = head\n",
        "\n",
        "    for dep in heads:\n",
        "        head = heads[dep]\n",
        "        left, right = min(head, dep), max(head, dep)\n",
        "        for i in range(left + 1, right):\n",
        "            if not reachable(i, head, heads): return False\n",
        "            \n",
        "    return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCZUcO60jKcW",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.a.\n",
        "Implement the first helper function `perform_shift` to achieve the SHIFT operation.\n",
        "* The SHIFT Operation removes word from front of input buffer and push it onto stack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFzJksVqjKcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_shift(wbuffer, stack, arcs,\n",
        "                  configurations, gold_transitions):\n",
        "    \"\"\"\n",
        "    perform the SHIFT operation\n",
        "    \"\"\"\n",
        "\n",
        "    # Implement your code below\n",
        "    # your code should:\n",
        "    # 1. append the latest configuration to configurations\n",
        "    # 2. append the latest action to gold_transitions\n",
        "    # 3. update wbuffer, stack and arcs accordingly\n",
        "    # hint: note that the order of operations matters\n",
        "    # as we want to capture the configurations and transition rules\n",
        "    # before making changes to the stack, wbuffer and arcs\n",
        "    \n",
        "    ##################\n",
        "    # YOUR CODE HERE\n",
        "    ##################\n",
        "\n",
        "    ##################\n",
        "    # Staff Solution\n",
        "    ##################\n",
        "\n",
        "    configurations.append((list(wbuffer), list(stack), list(arcs)))\n",
        "    gold_transitions.append(\"SHIFT\")\n",
        "    stack.append(wbuffer.pop())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxqIrNnzjKcb",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.b.\n",
        "Implement the second helper function `perform_arc` to achieve the ARC operation.\n",
        "\n",
        "* LEFT-ARC (label): assert relation between head at $stack_1$ and dependent at $stack_2$: remove $stack_2$\n",
        "* RIGHT-ARC (label): assert relation between head at $stack_2$ and dependent at $stack_1$; remove $stack_1$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW9_Y2fyjKcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def perform_arc(direction, dep_label,\n",
        "                wbuffer, stack, arcs,\n",
        "                configurations, gold_transitions):\n",
        "    \"\"\"\n",
        "    params:\n",
        "        - direction: {\"LEFT\", \"RIGHT\"}\n",
        "        - dep_label: label for the dependency relations\n",
        "    Perform LEFTARC_ and RIGHTARC_ operations\n",
        "    \"\"\"\n",
        "\n",
        "    # Implement your code below\n",
        "    # your code should:\n",
        "    # 1. append the latest configuration to configurations\n",
        "    # 2. append the latest action to gold_transitions\n",
        "    # 3. update wbuffer, stack and arcs accordingly\n",
        "    # hint: note that the order of operations matters\n",
        "    # as we want to capture the configurations and transition rules\n",
        "    # before making changes to the stack, wbuffer and arcs\n",
        "\n",
        "    ##################\n",
        "    # YOUR CODE HERE\n",
        "    ##################\n",
        "\n",
        "    ##################\n",
        "    # Staff Solution\n",
        "    ##################\n",
        "\n",
        "    if direction == \"LEFT\": (head, child) = (stack[-1], stack[-2])\n",
        "    else: (head, child) = (stack[-2], stack[-1])\n",
        "\n",
        "    # update configurations and transition rules\n",
        "    configurations.append((list(wbuffer), list(stack), list(arcs)))\n",
        "    gold_transitions.append(\"{}ARC_{}\".format(direction, dep_label))\n",
        "\n",
        "    # update arcs, stack and wbuffer\n",
        "    arcs.append((dep_label, head, child))\n",
        "\n",
        "    if direction == \"LEFT\": stack.pop(-2)\n",
        "    else: stack.pop()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmDSyQpqjKcg",
        "colab_type": "text"
      },
      "source": [
        "### Question 2.c.\n",
        "Now, since we have implemented the helper functions, let's use them to complete `tree_to_actions`.\n",
        "\n",
        "`tree_to_actions` takes wbuffer, stack, arcs and deps as input, returns configuration of the parser and action for the parser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HeTVArDjKci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tree_to_actions(wbuffer, stack, arcs, deps):\n",
        "    \"\"\"\n",
        "    params:\n",
        "    wbuffer: a list of word indices; the top of buffer is at the end of the list\n",
        "    stack: a list of word indices; the top of buffer is at the end of the list\n",
        "    arcs: a list of (label, head, dependent) tuples\n",
        "\n",
        "    Given wbuffer, stack, arcs and deps\n",
        "    Return configurations and gold_transitions (actions)\n",
        "    \"\"\"\n",
        "\n",
        "    # configurations:\n",
        "    # A list of tuples of lists\n",
        "    # [(wbuffer1, stack1, arcs1), (wbuffer2, stack2, arcs2), ...]\n",
        "    # Keeps tracks of the states at each step\n",
        "    configurations=[]\n",
        "\n",
        "    # gold_transitions:\n",
        "    # A list of action strings, e.g [\"SHIFT\", \"LEFTARC_nsubj\"]\n",
        "    # Keeps tracks of the actions at each step\n",
        "    gold_transitions=[]\n",
        "\n",
        "    # Implement your code below\n",
        "    # hint:\n",
        "    # 1. configurations[i] and gold_transitions[i] should\n",
        "    # correspond to the states of the wbuffer, stack, arcs\n",
        "    # (before the action was taken) and action to take at step i\n",
        "    # 2. you should call perform_shift and perform_arc in your code\n",
        "    \n",
        "\n",
        "    ##################\n",
        "    # YOUR CODE HERE\n",
        "    ##################\n",
        "\n",
        "    ##################\n",
        "    # Staff Solution\n",
        "    ##################\n",
        "    dep_arcs = {}\n",
        "\n",
        "    while len(wbuffer) >= 0:\n",
        "        # we have translated all the tree to transition instructions\n",
        "        if len(wbuffer) == 0 and len(stack) == 1 and stack[0] == 0:\n",
        "            return configurations, gold_transitions\n",
        "\n",
        "        # when there're fewer than 2 words on the stack\n",
        "        # and more than 0 left on the buffer, shift\n",
        "        if len(stack) < 2 and len(wbuffer) > 0:\n",
        "            # shift operations\n",
        "            perform_shift(wbuffer, stack, arcs,\n",
        "                configurations, gold_transitions)\n",
        "            continue\n",
        "\n",
        "        stack1 = stack[-1]\n",
        "        stack2 = stack[-2]\n",
        "\n",
        "        # 1. check against conditions for left arc operation\n",
        "        if stack1 in deps and (stack1, stack2) in deps[stack1]:\n",
        "            perform_arc(\"LEFT\", deps[stack1][(stack1, stack2)],\n",
        "                    wbuffer, stack, arcs,\n",
        "                    configurations, gold_transitions)\n",
        "            dep_arcs[stack2] = 1\n",
        "\n",
        "        # 2. check against conditions for right arc operation\n",
        "        elif stack2 in deps and (stack2, stack1) in deps[stack2]:\n",
        "            (head, dep) = (stack2, stack1)\n",
        "\n",
        "            # check if all of the dependents of the word at\n",
        "            # the top of the stack have already been assigned\n",
        "            children_added = True\n",
        "            if dep in deps:\n",
        "                for (_, child) in deps[dep]:\n",
        "                    if child not in dep_arcs:\n",
        "                        children_added = False\n",
        "\n",
        "            # if so, perform right arc operation\n",
        "            if children_added == True:\n",
        "                perform_arc(\"RIGHT\", deps[head][(head, dep)],\n",
        "                        wbuffer, stack, arcs,\n",
        "                        configurations, gold_transitions)\n",
        "                dep_arcs[dep] = 1\n",
        "\n",
        "            # otherwise, perform shift\n",
        "            else:\n",
        "                perform_shift(wbuffer, stack, arcs,\n",
        "                    configurations, gold_transitions)\n",
        "\n",
        "        # 3. perform shift\n",
        "        else:\n",
        "            perform_shift(wbuffer, stack, arcs,\n",
        "                configurations, gold_transitions)            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlLh-Q_sjKcl",
        "colab_type": "text"
      },
      "source": [
        "### Question 3. Tree Parsing with Predictions\n",
        "Implementaction_to_tree, which will update the dependency tree based on the action predictions.\n",
        "* Don't forget to use `isvalid` to check the validity of the possible actions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFTfAwLWjKcm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isvalid(stack, wbuffer, action):\n",
        "    \"\"\"\n",
        "    Helper function that returns True only if an action is\n",
        "    legal given the current states of the stack and wbuffer\n",
        "    \"\"\"\n",
        "    if action == \"SHIFT\" and len(wbuffer) > 0:\n",
        "        return True\n",
        "    if action.startswith(\"RIGHTARC\") and len(stack) > 1 and stack[-1] != 0:\n",
        "        return True\n",
        "    if action.startswith(\"LEFTARC\") and len(stack) > 1 and stack[-2] != 0:\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH_vzMzRjKcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def action_to_tree(tree, predictions, wbuffer, stack, arcs, reverse_labels):\n",
        "    \"\"\"\n",
        "    params:\n",
        "    tree:\n",
        "    a dictionary of dependency relations (head, dep_label)\n",
        "        {\n",
        "            child1: (head1, dep_lebel1),\n",
        "            child2: (head2, dep_label2), ...\n",
        "        }\n",
        "\n",
        "    predictions:\n",
        "    a numpy column vector of probabilities for different dependency labels\n",
        "    as ordered by the variable reverse_labels\n",
        "    predictions.shape = (1, total number of dependency labels)\n",
        "\n",
        "    wbuffer: a list of word indices; top of buffer is at the end of the list\n",
        "    stack: a list of word indices; top of stack is at the end of the list\n",
        "    arcs: a list of (label, head, dependent) tuples\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Implement your code below\n",
        "    # hint:\n",
        "    # 1. the predictions contains the probability distribution for all\n",
        "    # possible actions for a single step, and you should choose one\n",
        "    # and update the tree only once\n",
        "    # 2. some actions predicted are not going to be valid\n",
        "    # (e.g., shifting if nothing is on the buffer)\n",
        "    # so sort probs and keep going until you find one that is valid.\n",
        "    \n",
        "    ##################\n",
        "    # YOUR CODE HERE\n",
        "    ##################\n",
        "\n",
        "    ##################\n",
        "    # Staff Solution\n",
        "    ##################\n",
        "    sorted_probs = np.argsort(-predictions, kind='quicksort')[0]\n",
        "\n",
        "    for i in range(len(sorted_probs)):\n",
        "        action = reverse_labels[sorted_probs[i]]\n",
        "        if isvalid(stack, wbuffer, action):\n",
        "            if action == \"SHIFT\":\n",
        "                stack.append(wbuffer.pop())\n",
        "\n",
        "            elif len(stack) > 1 and action.startswith(\"RIGHTARC\"):\n",
        "                tree[stack[-1]] = (stack[-2], re.sub(\"RIGHTARC_\", \"\", action))\n",
        "                stack.pop()\n",
        "\n",
        "            elif len(stack) > 1 and action.startswith(\"LEFTARC\"):\n",
        "                tree[stack[-2]] = (stack[-1], re.sub(\"LEFTARC_\", \"\", action))\n",
        "                stack.pop(-2)\n",
        "\n",
        "            break          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJsWiPY5jKcu",
        "colab_type": "text"
      },
      "source": [
        "### Implemented for you\n",
        "Now since you have the configuration $x$ and action $y$, we can now train a supervised model to predict an action $y$ given a configuration $x$. We are using a simplified version model of [A Fast and Accurate Dependency Parser using Neural Networks](https://nlp.stanford.edu/pubs/emnlp2014-depparser.pdf).\n",
        "\n",
        "* This model is alreadly implemented for you, please `train` the model, and report the evaluate and test results by calling the function `evaluate` and `test`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlx_IRrJjKcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ============================================================\n",
        "# THE FOLLOWING CODE IS PROVIDED\n",
        "# ============================================================\n",
        "def get_oracle(toks):\n",
        "    \"\"\"\n",
        "    Return pairs of configurations + gold transitions (actions)\n",
        "    from training data\n",
        "    configuration = a list of tuple of:\n",
        "        - buffer (top of buffer is at the end of the list)\n",
        "        - stack (top of buffer is at the end of the list)\n",
        "        - arcs (a list of (label, head, dependent) tuples)\n",
        "    gold transitions = a list of actions, e.g. SHIFT\n",
        "    \"\"\"\n",
        "\n",
        "    stack = [] # stack\n",
        "    arcs = [] # existing list of arcs\n",
        "    wbuffer = [] # input buffer\n",
        "\n",
        "    # deps is a dictionary of head: dependency relations, where\n",
        "    # dependency relations is a dictionary of the (head, child): label\n",
        "    # deps = {head1:{\n",
        "    #               (head1, child1):dependency_label1,\n",
        "    #               (head1, child2):dependency_label2\n",
        "    #              }\n",
        "    #         head2:{\n",
        "    #               (head2, child3):dependency_label3,\n",
        "    #               (head2, child4):dependency_label4\n",
        "    #              }\n",
        "    #         }\n",
        "    deps = {}\n",
        "\n",
        "    # ROOT\n",
        "    stack.append(0)\n",
        "\n",
        "    # initialize variables\n",
        "    for position in reversed(toks):\n",
        "        (idd, _, _, head, lab) = position\n",
        "\n",
        "        dep = (head, idd)\n",
        "        if head not in deps:\n",
        "            deps[head] = {}\n",
        "        deps[head][dep] = lab\n",
        "\n",
        "        wbuffer.append(idd)\n",
        "\n",
        "    # configurations:\n",
        "    # A list of (wbuffer, stack, arcs)\n",
        "    # Keeps tracks of the states at each step\n",
        "    # gold_transitions:\n",
        "    # A list of action strings [\"SHIFT\", \"LEFTARC_nsubj\"]\n",
        "    # Keeps tracks of the actions at each step\n",
        "    configurations, gold_transitions = tree_to_actions(wbuffer, stack, arcs, deps)\n",
        "    return configurations, gold_transitions\n",
        "\n",
        "def featurize_configuration(configuration, tokens, postags, vocab, pos_vocab):\n",
        "\n",
        "    def get_id(word, vocab):\n",
        "        word=word.lower()\n",
        "        if word in vocab:\n",
        "            return vocab[word]\n",
        "        return vocab[\"<unk>\"]\n",
        "\n",
        "    \"\"\"\n",
        "    Given configurations of the stack, input buffer and arcs,\n",
        "    words of the sentence and POS tags of the words,\n",
        "    return some features\n",
        "\n",
        "    The current features are the word ID and postag ID at the \n",
        "    first three positions of the stack and buffer.\n",
        "    \"\"\"\n",
        "\n",
        "    wbuffer, stack, arcs = configuration\n",
        "\n",
        "    word_features=[]\n",
        "    pos_features=[]\n",
        "\n",
        "    if len(stack) > 0: \n",
        "        word_features.append(get_id(tokens[stack[-1]], vocab))\n",
        "        pos_features.append(get_id(postags[stack[-1]], pos_vocab))\n",
        "    else: \n",
        "        word_features.append(get_id(\"<NONE>\", vocab))\n",
        "        pos_features.append(get_id(\"<NONE>\", pos_vocab))\n",
        "\n",
        "    if len(stack) > 1: \n",
        "        word_features.append(get_id(tokens[stack[-2]], vocab))\n",
        "        pos_features.append(get_id(postags[stack[-2]], pos_vocab))\n",
        "    else: \n",
        "        word_features.append(get_id(\"<NONE>\", vocab))\n",
        "        pos_features.append(get_id(\"<NONE>\", pos_vocab))\n",
        "\n",
        "    if len(stack) > 2: \n",
        "        word_features.append(get_id(tokens[stack[-3]], vocab))\n",
        "        pos_features.append(get_id(postags[stack[-3]], pos_vocab))\n",
        "    else: \n",
        "        word_features.append(get_id(\"<NONE>\", vocab))\n",
        "        pos_features.append(get_id(\"<NONE>\", pos_vocab))\n",
        "\n",
        "    if len(wbuffer) > 0: \n",
        "        word_features.append(get_id(tokens[wbuffer[-1]], vocab))\n",
        "        pos_features.append(get_id(postags[wbuffer[-1]], pos_vocab))\n",
        "    else: \n",
        "        word_features.append(get_id(\"<NONE>\", vocab))\n",
        "        pos_features.append(get_id(\"<NONE>\", pos_vocab))\n",
        "       \n",
        "    if len(wbuffer) > 1: \n",
        "        word_features.append(get_id(tokens[wbuffer[-2]], vocab))\n",
        "        pos_features.append(get_id(postags[wbuffer[-2]], pos_vocab))\n",
        "    else: \n",
        "        word_features.append(get_id(\"<NONE>\", vocab))\n",
        "        pos_features.append(get_id(\"<NONE>\", pos_vocab))\n",
        "\n",
        "    if len(wbuffer) > 2: \n",
        "        word_features.append(get_id(tokens[wbuffer[-3]], vocab))\n",
        "        pos_features.append(get_id(postags[wbuffer[-3]], pos_vocab))\n",
        "    else: \n",
        "        word_features.append(get_id(\"<NONE>\", vocab))\n",
        "        pos_features.append(get_id(\"<NONE>\", pos_vocab))\n",
        "\n",
        "    return word_features, pos_features\n",
        "\n",
        "\n",
        "def get_oracles(filename, vocab, tag_vocab):\n",
        "    \"\"\"\n",
        "    Get configurations, gold_transitions from all sentences\n",
        "    \"\"\"\n",
        "    with open(filename) as f:\n",
        "        toks, tokens, postags = [], {}, {}\n",
        "        tokens[0] = \"<ROOT>\"\n",
        "        postags[0] = \"<ROOT>\"\n",
        "\n",
        "        # a list of all features for each transition step\n",
        "        word_feats = []\n",
        "        pos_feats = []\n",
        "        # a list of labels, e.g. SHIFT, LEFTARC_DEP_LABEL, RIGHTARC_DEP_LABEL\n",
        "        labels = []\n",
        "\n",
        "        for line in f:\n",
        "            cols = line.rstrip().split(\"\\t\")\n",
        "            \n",
        "            if len(cols) < 2: # at the end of each sentence\n",
        "                if len(toks) > 0:\n",
        "                    if is_projective(toks): # only use projective trees\n",
        "                        # get all configurations and gold standard transitions\n",
        "                        configurations, gold_transitions = get_oracle(toks)\n",
        "                        \n",
        "                        for i in range(len(configurations)):\n",
        "                            word_feat, pos_feat = featurize_configuration(configurations[i], tokens, postags, vocab, tag_vocab)\n",
        "                            label = gold_transitions[i]\n",
        "                            word_feats.append(word_feat)\n",
        "                            pos_feats.append(pos_feat)\n",
        "                            labels.append(label)\n",
        "\n",
        "                    # reset vars for the next sentence\n",
        "                    toks, tokens, postags = [], {}, {}\n",
        "                    tokens[0] = \"<ROOT>\"\n",
        "                    postags[0] = \"<ROOT>\"\n",
        "                    \n",
        "                continue\n",
        "\n",
        "            if cols[0].startswith(\"#\"):\n",
        "                continue\n",
        "\n",
        "            # construct the tuple for each word in the sentence\n",
        "            # for each word in the sentence\n",
        "            # idd: index of a word in a sentence, starting from 1\n",
        "            # tok: the word itself\n",
        "            # pos: pos tag for that word\n",
        "            # head: parent of the dependency\n",
        "            # lab: dependency relation label\n",
        "            idd, tok, pos, head, lab = int(cols[0]), cols[1], cols[4], int(cols[6]), cols[7]\n",
        "            toks.append((idd, tok, pos, head, lab))\n",
        "\n",
        "            # feature for training to predict the gold transition\n",
        "            tokens[idd], postags[idd] = tok, pos\n",
        "\n",
        "        return word_feats, pos_feats, labels\n",
        "\n",
        "def load_embeddings(filename):\n",
        "    # 0 idx is for padding\n",
        "    # 1 idx is for <UNK>\n",
        "    # 2 idx is for <NONE>\n",
        "    # 3 idx is for <ROOT>\n",
        "\n",
        "    # get the embedding size from the first embedding\n",
        "    vocab_size=4\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for idx, line in enumerate(file):\n",
        "            if idx == 0:\n",
        "                word_embedding_dim=len(line.rstrip().split(\" \"))-1\n",
        "            vocab_size+=1\n",
        "        \n",
        "\n",
        "    vocab={\"<pad>\":0, \"<unk>\":1, \"<none>\":2, \"<root>\":3}\n",
        "    print(\"word_embedding_dim: %s, vocab size: %s\" % (word_embedding_dim, vocab_size))\n",
        "\n",
        "    embeddings=np.zeros((vocab_size, word_embedding_dim))\n",
        "\n",
        "    with open(filename, encoding=\"utf-8\") as file:\n",
        "        for idx,line in enumerate(file):\n",
        "\n",
        "            if idx + 4 >= vocab_size:\n",
        "                break\n",
        "\n",
        "            cols=line.rstrip().split(\" \")\n",
        "            val=np.array(cols[1:])\n",
        "            word=cols[0]\n",
        "            embeddings[idx+4]=val\n",
        "            vocab[word]=idx+4\n",
        "\n",
        "    return torch.FloatTensor(embeddings), vocab\n",
        "\n",
        "class ShiftReduceParser(nn.Module):\n",
        "\n",
        "    def __init__(self, embeddings, hidden_dim, tagset_size, num_pos_tags, pos_embedding_dim):\n",
        "        super(ShiftReduceParser, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_labels=tagset_size\n",
        "\n",
        "        _, embedding_dim = embeddings.shape\n",
        "\n",
        "        self.input_size=embedding_dim*6 + pos_embedding_dim*6\n",
        "        \n",
        "        self.dropout_layer = nn.Dropout(p=0.25)\n",
        "\n",
        "        self.word_embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "        self.pos_embeddings = nn.Embedding(num_pos_tags, pos_embedding_dim)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "        self.W2 = nn.Linear(self.hidden_dim, self.num_labels)\n",
        "\n",
        "    def forward(self, words, pos_tags, Y=None):\n",
        "        \n",
        "        words=words.to(device)\n",
        "        pos_tags=pos_tags.to(device)\n",
        "\n",
        "        if Y is not None:\n",
        "            Y=Y.to(device)\n",
        "\n",
        "        word_embeds = self.word_embeddings(words)\n",
        "        postag_embeds = self.pos_embeddings(pos_tags)\n",
        "\n",
        "        embeds=torch.cat((word_embeds, postag_embeds), 2)\n",
        "\n",
        "        embeds=embeds.view(-1, self.input_size)\n",
        "\n",
        "        embeds=self.dropout_layer(embeds)\n",
        "\n",
        "        hidden = self.W1(embeds)\n",
        "        hidden = self.tanh(hidden)\n",
        "        logits = self.W2(hidden)\n",
        "\n",
        "        if Y is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), Y.view(-1))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "def get_batches(W, P, Y, batch_size):\n",
        "    batch_W=[]\n",
        "    batch_P=[]\n",
        "    batch_Y=[]\n",
        "\n",
        "    i=0\n",
        "    while i < len(W):\n",
        "        batch_W.append(torch.LongTensor(W[i:i+batch_size]))\n",
        "        batch_P.append(torch.LongTensor(P[i:i+batch_size]))\n",
        "        batch_Y.append(torch.LongTensor(Y[i:i+batch_size]))\n",
        "        i+=batch_size  \n",
        "\n",
        "    return batch_W, batch_P, batch_Y\n",
        "\n",
        "def train(word_feats, pos_feats, labels, embeddings, vocab, postag_vocab, label_vocab):\n",
        "    \"\"\"\n",
        "\n",
        "    Train transition-based parser to predict next action (labels)\n",
        "    given current configuration (featurized by word_feats and pos_feats)\n",
        "    Return the classifier trained using Chen and Manning (2014), \"A Fast \n",
        "    and Accurate Dependency Parser using Neural Networks\"\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # dimensionality of linear layer\n",
        "    HIDDEN_DIM=100\n",
        "    # dimensionality of POS embeddings\n",
        "    POS_EMBEDDING_SIZE=50\n",
        "\n",
        "    # batch size for training\n",
        "    BATCH_SIZE=32\n",
        "\n",
        "    # number of epochs to train for\n",
        "    NUM_EPOCHS=10\n",
        "\n",
        "    # learning rate for Adam optimizer\n",
        "    LEARNING_RATE=0.001\n",
        "\n",
        "    num_labels=[]\n",
        "    for i, y in enumerate(labels):\n",
        "        num_labels.append(label_vocab[y])\n",
        "\n",
        "    batch_W, batch_P, batch_Y = get_batches(word_feats, pos_feats, num_labels, BATCH_SIZE)\n",
        "\n",
        "    model = ShiftReduceParser(embeddings, HIDDEN_DIM, len(label_vocab), len(postag_vocab), POS_EMBEDDING_SIZE)\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "\n",
        "        bigloss=0.\n",
        "        for b in range(len(batch_W)):\n",
        "            model.zero_grad()\n",
        "\n",
        "            loss = model.forward(batch_W[b], batch_P[b], Y=batch_Y[b])\n",
        "            bigloss+=loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"loss: \", bigloss)\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def parse(toks, model, vocab, tag_vocab, reverse_labels):\n",
        "    \"\"\"\n",
        "    parse sentence with trained model and return correctness measure\n",
        "    \"\"\"\n",
        "    tokens, postags = {}, {}\n",
        "    tokens[0] = \"<ROOT>\"\n",
        "    postags[0] = \"<ROOT>\"\n",
        "\n",
        "    wbuffer, stack, arcs = [], [], []\n",
        "    stack.append(0)\n",
        "\n",
        "    for position in reversed(toks):\n",
        "\n",
        "        (idd, tok, pos, head, lab) = position\n",
        "        tokens[idd] = tok\n",
        "        postags[idd] = pos\n",
        "\n",
        "        # update buffer\n",
        "        wbuffer.append(idd)\n",
        "\n",
        "    tree = {}\n",
        "    while len(wbuffer) >= 0:\n",
        "        if len(wbuffer) == 0 and len(stack) == 0: break\n",
        "        if len(wbuffer) == 0 and len(stack) == 1 and stack[0] == 0: break\n",
        "\n",
        "        word_feats, pos_feats = (featurize_configuration((wbuffer, stack, arcs), tokens, postags, vocab, tag_vocab))\n",
        "\n",
        "       \n",
        "        predictions=model.forward(torch.LongTensor([word_feats]), torch.LongTensor([pos_feats]))\n",
        "\n",
        "        predictions=predictions.detach().cpu().numpy()\n",
        "\n",
        "        # your function will be called here\n",
        "        action_to_tree(tree, predictions, wbuffer, stack, arcs, reverse_labels)\n",
        "\n",
        "    return tree\n",
        "\n",
        "def parse_and_evaluate(toks, model, vocab, tag_vocab, reverse_labels):\n",
        "    \"\"\"\n",
        "    parse sentence with trained model and return correctness measure\n",
        "    \"\"\"\n",
        "\n",
        "    heads, labels = {}, {}\n",
        "\n",
        "    for position in reversed(toks):\n",
        "        (idd, tok, pos, head, lab) = position\n",
        "\n",
        "        # keep track of gold standards for performance evaluation\n",
        "        heads[idd], labels[idd] = head, lab\n",
        "\n",
        "    tree = parse(toks, model, vocab, tag_vocab, reverse_labels)\n",
        "\n",
        "    # correct_unlabeled: total number of correct (head, child) dependencies\n",
        "    # correct_labeled: total number of correctly *labeled* dependencies\n",
        "    correct_unlabeled, correct_labeled, total = 0, 0, 0\n",
        "\n",
        "    for child in tree:\n",
        "        (head, label) = tree[child]\n",
        "        if head == heads[child]:\n",
        "            correct_unlabeled += 1\n",
        "            if label == labels[child]: correct_labeled += 1\n",
        "        total += 1\n",
        "\n",
        "    return [correct_unlabeled, correct_labeled, total]\n",
        "\n",
        "def get_label_vocab(labels):\n",
        "    tag_vocab={}\n",
        "    num_labels=[]\n",
        "    for i, y in enumerate(labels):\n",
        "        if y not in tag_vocab:\n",
        "            tag_vocab[y]=len(tag_vocab)\n",
        "        num_labels.append(tag_vocab[y])\n",
        "\n",
        "    reverse_labels=[None]*len(tag_vocab)\n",
        "    for y in tag_vocab:\n",
        "        reverse_labels[tag_vocab[y]]=y\n",
        "\n",
        "    return tag_vocab, reverse_labels\n",
        "\n",
        "\n",
        "def get_pos_tag_vocab(filename):\n",
        "    tag_vocab={\"<none>\":0, \"<unk>\":1}\n",
        "    with open(filename) as file:\n",
        "        for line in file:\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "            if len(cols) < 3:\n",
        "                continue\n",
        "            pos=cols[4].lower()\n",
        "            if pos not in tag_vocab:\n",
        "                tag_vocab[pos]=len(tag_vocab)\n",
        "    return tag_vocab\n",
        "\n",
        "def test(model, vocab, tag_vocab, reverse_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a parser against gold standard\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    toks=[\"I\", \"bought\", \"a\", \"book\"]\n",
        "    pos=[\"NNP\", \"VBD\", \"DT\", \"NN\"]\n",
        "\n",
        "    data=[]\n",
        "    # put it in format parser expects\n",
        "    for i, tok in enumerate(toks):\n",
        "        data.append((i+1, tok, pos[i], \"_\", \"_\"))\n",
        "\n",
        "    tree=parse(data, model, vocab, tag_vocab, reverse_labels)\n",
        "\n",
        "    for child in sorted(tree.keys()):\n",
        "        (head, label) = tree[child]\n",
        "        headStr=\"<ROOT>\"\n",
        "        if head > 0: # child and head indexes start at 1; 0 denotes the <ROOT>\n",
        "            headStr=toks[head-1]\n",
        "\n",
        "        print(\"(%s %s) -> (%s %s) %s\" % (child, toks[child-1], head, headStr, label))\n",
        "  \n",
        "\n",
        "\n",
        "def evaluate(filename, model, vocab, tag_vocab, reverse_labels):\n",
        "    \"\"\"\n",
        "    Evaluate the performance of a parser against gold standard\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with open(filename) as f:\n",
        "        toks=[]\n",
        "        totals = np.zeros(3)\n",
        "        for line in f:\n",
        "            cols=line.rstrip().split(\"\\t\")\n",
        "\n",
        "            if len(cols) < 2: # end of a sentence\n",
        "                if len(toks) > 0:\n",
        "                    if is_projective(toks):\n",
        "                        tots = np.array(parse_and_evaluate(toks, model, vocab, tag_vocab, reverse_labels))\n",
        "                        totals += tots\n",
        "                        \n",
        "                    toks = []\n",
        "                continue\n",
        "\n",
        "            if cols[0].startswith(\"#\"):\n",
        "                continue\n",
        "\n",
        "            idd, tok, pos, head, lab = int(cols[0]), cols[1], cols[4], int(cols[6]), cols[7]\n",
        "            toks.append((idd, tok, pos, head, lab))\n",
        "        \n",
        "        print (\"UAS: %.3f, LAS:%.3f\" % (totals[0]/totals[2], totals[1]/totals[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax1VrekKjKcy",
        "colab_type": "text"
      },
      "source": [
        "### Train and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PweOgvvjKc0",
        "colab_type": "code",
        "outputId": "ed551ad2-9080-4e9a-ff80-4b56ef51142d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "embeddingsFile = \"glove.6B.50d.txt\"\n",
        "# trainFile = \"train.projective.short.conll\"\n",
        "trainFile = \"train.projective.conll\"\n",
        "devFile = \"dev.projective.conll\"\n",
        "\n",
        "embeddings, vocab=load_embeddings(embeddingsFile)\n",
        "pos_tag_vocab=get_pos_tag_vocab(trainFile)\n",
        "word_feats, pos_feats, labels = get_oracles(trainFile, vocab, pos_tag_vocab)\n",
        "\n",
        "label_vocab, reverse_labels=get_label_vocab(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_embedding_dim: 50, vocab size: 400004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFN4U_1ojKc5",
        "colab_type": "code",
        "outputId": "fb0147ae-c0b5-48cb-ca78-61b53cd6ec18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "model = train(word_feats, pos_feats, labels, embeddings, vocab, pos_tag_vocab, label_vocab)\n",
        "evaluate(devFile, model, vocab, pos_tag_vocab, reverse_labels)\n",
        "test(model, vocab, pos_tag_vocab, reverse_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  6601.075233221054\n",
            "loss:  5419.460885792971\n",
            "loss:  5188.688662156463\n",
            "loss:  5070.64913097024\n",
            "loss:  4984.917502835393\n",
            "loss:  4926.127534791827\n",
            "loss:  4861.512933596969\n",
            "loss:  4824.057479247451\n",
            "loss:  4798.395987719297\n",
            "loss:  4780.909127429128\n",
            "UAS: 0.756, LAS:0.686\n",
            "(1 I) -> (2 bought) nsubj\n",
            "(2 bought) -> (0 <ROOT>) root\n",
            "(3 a) -> (4 book) det\n",
            "(4 book) -> (2 bought) obj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzas-zZNjKc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9TZeiLLjKdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyLUTj-wjKdI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRzGFyjCjKdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wosrQJaAjKdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6PdWLqGjKdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-90WLll5jKdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}